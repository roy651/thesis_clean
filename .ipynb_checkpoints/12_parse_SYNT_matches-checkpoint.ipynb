{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import os\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "from skimage.filters import threshold_otsu, threshold_adaptive, rank\n",
    "from skimage.morphology import disk\n",
    "from skimage.feature import match_template\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "# Pandas is used for data manipulation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# READ crops\n",
    "crops = {}\n",
    "with open('crops.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames=(\"file\",\"x_start\",\"y_start\",\"x_end\",\"y_end\",\"rotate\",\"horiz\",\"upside\"))\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        row['name'] = row['file'].split(\"/\")[5] # stay with the folder name\n",
    "        row['name'] = row['name'].split(\"-\")\n",
    "        row['name'] = row['name'][0] + row['name'][1] # set the short name...\n",
    "        row['x_start'] = int(row['x_start'])\n",
    "        row['y_start'] = int(row['y_start'])\n",
    "        row['x_end'] = int(row['x_end'])\n",
    "        row['y_end'] = int(row['y_end'])\n",
    "        # import pdb; pdb.set_trace()\n",
    "        row['rotate'] = True if row['rotate'] == 'True' else False\n",
    "        crops[row['name']] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UTILITY func\n",
    "cube_size = 250\n",
    "HORIZ_TOLERANCE_FACTOR = 50\n",
    "VERT_TOLERANCE_FACTOR = 75\n",
    "EDGE_GAP = 50\n",
    "\n",
    "# Simple crop by x/y ranges\n",
    "def crop(image, ymin, ymax, xmin, xmax):\n",
    "    return image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "\n",
    "def calc_combined_coordinates(base_x, base_y, offset_x, offset_y, base_rotate, base_x_end):\n",
    "    if base_rotate:\n",
    "        result_x = base_x_end - cube_size - offset_y # 250==CUBE_SIZE\n",
    "        result_y = base_y + offset_x\n",
    "    else:\n",
    "        result_x = base_x + offset_x\n",
    "        result_y = base_y + offset_y\n",
    "    return result_x, result_y\n",
    "\n",
    "\n",
    "imgs_root = \"/Volumes/250GB/PAPYRI/\"\n",
    "cropped_root = \"/Volumes/250gb/cropped2\"\n",
    "\n",
    "def load_img_for_name(file_name):\n",
    "    name_parts = file_name.split(\"-\")\n",
    "    img_path = imgs_root + name_parts[0] + \"/\" + \\\n",
    "        name_parts[0] + \"-\" + name_parts[1] + \"-\" + name_parts[2] + \"/\" + \\\n",
    "        file_name + \" _018.jpg\"\n",
    "    return img.imread(img_path)\n",
    "\n",
    "def load_cropped_for_name(file_name):\n",
    "    img_path = cropped_root + \"/\" + file_name + \" _018.jpg.npy\"\n",
    "    return np.load(img_path)\n",
    "\n",
    "def load_front_for_name(file_name):\n",
    "    front_file_name = file_name.replace(\"-V-\",\"-R-\")\n",
    "    name_parts = front_file_name.split(\"-\")\n",
    "    unique_part = name_parts[0] + \"-\" + name_parts[1] + \"-\" + name_parts[2]\n",
    "    img_path = imgs_root + name_parts[0] + \"/\" + \\\n",
    "         unique_part + \"/\"\n",
    "    \n",
    "    for root, dirs, files in os.walk(img_path):\n",
    "        for file_ in files:\n",
    "            if (\" _018\" in file_):        \n",
    "                return img.imread(img_path + file_)\n",
    "    \n",
    "# Pre-process the validation set\n",
    "def folder_walker(path, full_path, filter_text=\"\"):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file_ in files:\n",
    "            if \"-V-\" in file_ and not file_.startswith(\".\"):\n",
    "                if (filter_text == \"\" or filter_text in file_):\n",
    "                    # print(os.path.join(root, file_))\n",
    "                    if full_path:\n",
    "                        result.append( os.path.join(root, file_) )\n",
    "                    else:\n",
    "                        result.append(file_)\n",
    "    return result\n",
    "\n",
    "no_rotate = folder_walker(\"/Volumes/250GB/no_rotate\", False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CALC basic voting metrics per fragment and per side ALSO accumulate matches per fragment for trend (later)\n",
    "count = 0\n",
    "fragmentTotal = {} # Total number of fragments: usually indication of the size of the fragment\n",
    "fragmentVote = {} # basic fragment voting: one fragment vote per one match regardless of the side of the fragment\n",
    "fragmentAndSideTotal = {} # Total number of fragments per side: usually indication of the size of the side\n",
    "fragmentAndSideVote = {} # basic fragment-side voting: one fragment-side vote per one match on the specific side\n",
    "fragmentAndSideTrend = {}\n",
    "fragmentAndSideCubes = {}\n",
    "fragmentAndSideClass = {}\n",
    "fragmentAndSidePrediction = {}\n",
    "origCoordinates = {}\n",
    "fragmentNames = {}\n",
    "matchFirstFile = {}\n",
    "matchSecondFile = {}\n",
    "firstNames = {}\n",
    "secondNames = {}\n",
    "fragmentAndSideDrawRect = {}\n",
    "fragmentAndSideMatchPoint = {}\n",
    "\n",
    "\n",
    "with open('20181026_222409_synt_all.csv') as csvfile:\n",
    "    # reader = csv.DictReader(csvfile, fieldnames=(\"firstName\",\"secondName\",\"gap\"))\n",
    "    reader = csv.DictReader(csvfile, fieldnames=(\"concatName\", \"class\", \"prediction\", \"is_enriched\"))\n",
    "#     import pdb; pdb.set_trace()\n",
    "    for row in reader:\n",
    "        if row[\"is_enriched\"] == 'True':\n",
    "            continue\n",
    "        # split the first file name and calc the row and col\n",
    "        concatName = row[\"concatName\"]\n",
    "        # /home/il239838/files/train_concats3/1=PX303-Fg006-V-C02-R02_TEAR_5X3_PIECE_3X2_870_1745---PX303-Fg006-V-C02-R02_TEAR_5X3_PIECE_4X2_620_50\n",
    "        concatName = concatName[concatName.rfind('/')+1:]\n",
    "        concatClass = concatName[2] # redundant? essentially we're getting it below from the class field...\n",
    "        concatName = concatName[4:]\n",
    "        # PX303-Fg006-V-C02-R02_TEAR_5X3_PIECE_3X2_870_1745---PX303-Fg006-V-C02-R02_TEAR_5X3_PIECE_4X2_620_50\n",
    "        \n",
    "        firstName = concatName[0:concatName.find('---')]\n",
    "        secondName = concatName[concatName.find('---')+3:]\n",
    "        \n",
    "        split = firstName.split(\"_\")\n",
    "        row['firstNameOrig'] = split[0]\n",
    "        row['firstRow'] = int(int(split[5]) / 250)\n",
    "        row['firstY'] = int(split[5])\n",
    "        row['firstCol'] = int(int(split[6]) / 250)\n",
    "        row['firstSide'] = 0 if row['firstCol'] == 0 else 1\n",
    "        row['firstX'] = int(split[6])\n",
    "        fileSplit = row['firstNameOrig'].split(\"-\")\n",
    "        row['firstName'] = fileSplit[0] + fileSplit[1] + \"_\" + split[2] + \"_\" + split[4]\n",
    "\n",
    "        # split the second file name and calc the row and col\n",
    "        split = secondName.split(\"_\")\n",
    "        row['secondNameOrig'] = split[0]\n",
    "        row['secondRow'] = int(int(split[5]) / 250)\n",
    "        row['secondY'] = int(split[5])\n",
    "        row['secondCol'] = int(int(split[6]) / 250)\n",
    "        row['secondSide'] = 0 if row['secondCol'] == 0 else 1\n",
    "        row['secondX'] = int(split[6])\n",
    "        fileSplit = row['secondNameOrig'].split(\"-\")\n",
    "        row['secondName'] = fileSplit[0] + fileSplit[1] + \"_\" + split[2] + \"_\" + split[4]\n",
    "            \n",
    "        row['matchFragmentKey'] = row['firstName'] + \"_\" + row['secondName']\n",
    "        if row['matchFragmentKey'] not in fragmentTotal: # init on the first encounter with a pair key\n",
    "            fragmentVote[row['matchFragmentKey']] = 0\n",
    "            fragmentTotal[row['matchFragmentKey']] = 0\n",
    "        \n",
    "        fragmentTotal[row['matchFragmentKey']] += 1\n",
    "        fragmentVote[row['matchFragmentKey']] += int(row['prediction'])\n",
    "        \n",
    "        row['matchFragmentAndSideKey'] = row['firstName'] + \"_\" + str(row['firstSide']) \\\n",
    "            + \"_\" + row['secondName'] + \"_\" + str(row['secondSide'])\n",
    "        if row['matchFragmentAndSideKey'] not in fragmentAndSideVote: # init on the first encounter with the side-key\n",
    "            fragmentAndSideClass[row['matchFragmentAndSideKey']] = 0\n",
    "            fragmentAndSidePrediction[row['matchFragmentAndSideKey']] = 0\n",
    "            fragmentAndSideTotal[row['matchFragmentAndSideKey']] = 0\n",
    "            fragmentAndSideVote[row['matchFragmentAndSideKey']] = 0\n",
    "            fragmentAndSideTrend[row['matchFragmentAndSideKey']] = []\n",
    "            fragmentAndSideCubes[row['matchFragmentAndSideKey']] = []\n",
    "            origCoordinates[row['matchFragmentAndSideKey']] = []\n",
    "            fragmentNames[row['matchFragmentAndSideKey']] = row['matchFragmentKey']\n",
    "            firstNames[row['matchFragmentAndSideKey']] = row['firstName']\n",
    "            secondNames[row['matchFragmentAndSideKey']] = row['secondName']\n",
    "            fragmentAndSideDrawRect[row['matchFragmentAndSideKey']] = []\n",
    "            fragmentAndSideMatchPoint[row['matchFragmentAndSideKey']] = []\n",
    "            \n",
    "\n",
    "        # we set the class for the training of the next phase's (RF) based on the actual/original class of the pair\n",
    "        # The other factors, related to voting (below), will rely upon the prediction so that the training will mimick\n",
    "        # the actual behaviour we have in the validation\n",
    "        if row['class'] == \"[0, 1]\":\n",
    "            fragmentAndSideClass[row['matchFragmentAndSideKey']] = 1\n",
    "\n",
    "        fragmentAndSidePrediction[row['matchFragmentAndSideKey']] = int(row['prediction'])\n",
    "        fragmentAndSideTotal[row['matchFragmentAndSideKey']] += 1\n",
    "        fragmentAndSideVote[row['matchFragmentAndSideKey']] += int(row['prediction'])\n",
    "        \n",
    "        if int(row['prediction']) == 1:\n",
    "            # basically, in synt matches, we only match on one side (first on left and second on right)    \n",
    "            # but I guess the non matched can sometimes be \"inverted\" in the sense that first is on the right side\n",
    "            # but I'm not sure it's relevant at all, sice we won't place them together, at least not in synt\n",
    "            # nonetheless, because this code should be similar to the real (non-synt) operation, we should take it into consideration in the layout\n",
    "            invert = True if row['firstCol'] == row['secondCol'] else False \n",
    "            fragmentAndSideTrend[row['matchFragmentAndSideKey']].append([invert, row['firstRow'], row['secondRow']])\n",
    "            \n",
    "            \n",
    "            fragmentAndSideCubes[row['matchFragmentAndSideKey']].append([row['firstX'], row['firstY'], row['secondX'], row['secondY']])\n",
    "\n",
    "            # probably need to fix the next line before moving to real matches to be able to handle flips - the x/y would not match\n",
    "            fragmentAndSideDrawRect[row['matchFragmentAndSideKey']].append([row['firstX'] + cube_size + EDGE_GAP - HORIZ_TOLERANCE_FACTOR, \n",
    "                                                                            row['firstY'] - row['secondY'] - VERT_TOLERANCE_FACTOR,\n",
    "                                                                            row['firstX'] + cube_size + EDGE_GAP + HORIZ_TOLERANCE_FACTOR, \n",
    "                                                                            row['firstY'] - row['secondY'] + VERT_TOLERANCE_FACTOR])\n",
    "            fragmentAndSideMatchPoint[row['matchFragmentAndSideKey']].append([row['firstX'] + cube_size + EDGE_GAP, \n",
    "                                                                              row['firstY'] - row['secondY']])\n",
    "\n",
    "#         firstCrop = crops[row['firstName']]\n",
    "#         firstXcombined, firstYCombined = \\\n",
    "#             calc_combined_coordinates(firstCrop['x_start'], firstCrop['y_start'], row['firstX'], row['firstY'], firstCrop['rotate'], firstCrop['x_end'])\n",
    "#         secondCrop = crops[row['secondName']]\n",
    "#         secondXcombined, secondYCombined = \\\n",
    "#             calc_combined_coordinates(secondCrop['x_start'], secondCrop['y_start'], row['secondX'], row['secondY'], secondCrop['rotate'], secondCrop['x_end'])\n",
    "#         origCoordinates[row['matchFragmentAndSideKey']].append([firstXcombined, firstYCombined, secondXcombined, secondYCombined])\n",
    "#         matchFirstFile[row['matchFragmentAndSideKey']] = row['firstNameOrig']\n",
    "#         matchSecondFile[row['matchFragmentAndSideKey']] = row['secondNameOrig']\n",
    "\n",
    "#         # print(row['firstName'], row['firstRow'], row['firstCol'], row['secondName'], row['secondRow'], row['secondCol'], row['gap'])\n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CALC simple trend voting\n",
    "fragmentAndSideTrendVote = {}\n",
    "for fragmanetAndSideKey in fragmentAndSideTrend:\n",
    "    is_reverse = False\n",
    "    if fragmentAndSideVote[fragmanetAndSideKey] > 0:\n",
    "        is_reverse = fragmentAndSideTrend[fragmanetAndSideKey][0][0]\n",
    "    fragmentAndSideVote[fragmanetAndSideKey]    \n",
    "    fragmentAndSideTrend[fragmanetAndSideKey] = sorted(fragmentAndSideTrend[fragmanetAndSideKey], key=itemgetter(2), reverse=is_reverse)\n",
    "    fragmentAndSideTrend[fragmanetAndSideKey] = sorted(fragmentAndSideTrend[fragmanetAndSideKey], key=itemgetter(1))\n",
    "    firstPrev = 0\n",
    "    secondPrev = 0\n",
    "    trend = 0\n",
    "    for match in fragmentAndSideTrend[fragmanetAndSideKey]:\n",
    "        if (match[1] - firstPrev) <= 1:\n",
    "            if match[0] and (secondPrev == 0 or (secondPrev - match[2]) <= 1): # match[0] == inverted\n",
    "                trend += 1\n",
    "            elif (match[2] - secondPrev) <= 1:\n",
    "                trend += 1\n",
    "        firstPrev = match[1]\n",
    "        secondPrev = match[2]\n",
    "    fragmentAndSideTrendVote[fragmanetAndSideKey] = trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CALC strict trend voting PLUS bonus for synchronized trend ALSO calc bonus separately\n",
    "fragmentAndSideTrendVoteStrict = {}\n",
    "fragmentAndSideTrendVoteSync = {}\n",
    "for fragmanetAndSideKey in fragmentAndSideCubes:\n",
    "    # import pdb; pdb.set_trace()\n",
    "    fragmentAndSideCubes[fragmanetAndSideKey] = sorted(fragmentAndSideCubes[fragmanetAndSideKey], key=itemgetter(2))\n",
    "    fragmentAndSideCubes[fragmanetAndSideKey] = sorted(fragmentAndSideCubes[fragmanetAndSideKey], key=itemgetter(0))\n",
    "    firstPrev = -1\n",
    "    secondPrev = -1\n",
    "    trend = 0\n",
    "    sync = 0\n",
    "    maxTrend = 0\n",
    "    for match in fragmentAndSideCubes[fragmanetAndSideKey]:\n",
    "        if firstPrev != -1:\n",
    "            if (match[0] - firstPrev) == 0:\n",
    "                if (match[2] - secondPrev) <= 250:\n",
    "                    trend += 1\n",
    "                else:\n",
    "                    trend = 0\n",
    "            elif (match[0] - firstPrev) <= 250:\n",
    "                if (match[2] - secondPrev) <= 250:\n",
    "                    trend += 2\n",
    "                    sync += 1\n",
    "                elif (match[2] - secondPrev) == 0:\n",
    "                    trend += 1\n",
    "                else:\n",
    "                    trend = 0\n",
    "        maxTrend = max(trend, maxTrend)\n",
    "        firstPrev = match[1]\n",
    "        secondPrev = match[2]\n",
    "    fragmentAndSideTrendVoteStrict[fragmanetAndSideKey] = maxTrend\n",
    "    fragmentAndSideTrendVoteSync[fragmanetAndSideKey] = sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WRITE results to a CSV file\n",
    "with open('20181026_222409_votes_cubes_match_synt_75.csv', 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',')\n",
    "    csvwriter.writerow([\"fragmentAndSide\", \n",
    "                        \"fragment\", \n",
    "                        \"fragmentTotal\",\n",
    "                        \"fragmentVote\",\n",
    "                        \"devideVoteByTotal\",\n",
    "                        \"fragmentAndSideTotal\",\n",
    "                        \"fragmentAndSideVote\",\n",
    "                        \"devideSideVoteBySideTotal\",\n",
    "                        \"fragmentAndSideTrendVote\",\n",
    "                        \"devideSideTrendVoteBySideTotal\",\n",
    "                        \"fragmentAndSideTrendVoteStrict\",\n",
    "                        \"devideSideTrendVoteStrictBySideTotal\",\n",
    "                        \"fragmentAndSideTrendVoteSync\",\n",
    "                        \"devideSideTrendVoteSyncBySideTotal\",\n",
    "\n",
    "                        \"firstFileName\",\n",
    "                        \"firstCroppedWidth\",\n",
    "                        \"firstOffsetX\",\n",
    "                        \"firstOffsetY\",\n",
    "                        \"firstHorizontalFlip\",\n",
    "                        \"secondFileName\",\n",
    "                        \"secondCroppedWidth\",\n",
    "                        \"secondOffsetX\",\n",
    "                        \"secondOffsetY\",\n",
    "                        \"secondHorizontalFlip\",                        \n",
    "                        \n",
    "                        \"fragmentAndSideTrend\",\n",
    "                        \"fragmentAndSideCubes\",\n",
    "                        \"fragmentAndSideDrawRect\",\n",
    "                        \"fragmentAndSideMatchPoint\",\n",
    "                        \"origCoordinates\",\n",
    "                        \"class\",\n",
    "                        \"prediction\"\n",
    "                       ])\n",
    "    for fragmanetAndSideKey in fragmentAndSideVote:\n",
    "        csvwriter.writerow([fragmanetAndSideKey, \n",
    "                            fragmentNames[fragmanetAndSideKey], \n",
    "                            fragmentTotal[fragmentNames[fragmanetAndSideKey]],\n",
    "                            fragmentVote[fragmentNames[fragmanetAndSideKey]],\n",
    "                            fragmentVote[fragmentNames[fragmanetAndSideKey]] / fragmentTotal[fragmentNames[fragmanetAndSideKey]],\n",
    "                            fragmentAndSideTotal[fragmanetAndSideKey],\n",
    "                            fragmentAndSideVote[fragmanetAndSideKey],\n",
    "                            fragmentAndSideVote[fragmanetAndSideKey] / fragmentAndSideTotal[fragmanetAndSideKey],\n",
    "                            fragmentAndSideTrendVote[fragmanetAndSideKey],\n",
    "                            fragmentAndSideTrendVote[fragmanetAndSideKey] / fragmentAndSideTotal[fragmanetAndSideKey],\n",
    "                            fragmentAndSideTrendVoteStrict[fragmanetAndSideKey],\n",
    "                            fragmentAndSideTrendVoteStrict[fragmanetAndSideKey] / fragmentAndSideTotal[fragmanetAndSideKey],\n",
    "                            fragmentAndSideTrendVoteSync[fragmanetAndSideKey],\n",
    "                            fragmentAndSideTrendVoteSync[fragmanetAndSideKey] / fragmentAndSideTotal[fragmanetAndSideKey],\n",
    "                            \n",
    "                            firstNames[fragmanetAndSideKey],\n",
    "                            0,\n",
    "                            0,\n",
    "                            0,\n",
    "                            0,\n",
    "                            secondNames[fragmanetAndSideKey],\n",
    "                            0,\n",
    "                            0,\n",
    "                            0,\n",
    "                            0,\n",
    "                            \n",
    "                            fragmentAndSideTrend[fragmanetAndSideKey],\n",
    "                            fragmentAndSideCubes[fragmanetAndSideKey],\n",
    "                            fragmentAndSideDrawRect[fragmanetAndSideKey],\n",
    "                            fragmentAndSideMatchPoint[fragmanetAndSideKey],\n",
    "                            origCoordinates[fragmanetAndSideKey],\n",
    "                            fragmentAndSideClass[fragmanetAndSideKey],\n",
    "                            fragmentAndSidePrediction[fragmanetAndSideKey]                            \n",
    "                           ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STOP HERE? NO!! Need the next 2 cells for the alignment of the flipped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UTIL 2 - needed functions for flipping and matching\n",
    "def find_match(big_img, small_img):\n",
    "    match_map = match_template(big_img, small_img)\n",
    "    offsets_arr = np.unravel_index(np.argmax(match_map), match_map.shape)\n",
    "    offset_x, offset_y = offsets_arr[::-1]        \n",
    "    return offset_x, offset_y, match_map[offsets_arr]\n",
    "  \n",
    "\n",
    "def extract_image_derivatives(file_name):\n",
    "    image = load_img_for_name(file_name)\n",
    "    split = file_name.split(\"-\")\n",
    "    short_name = split[0] + split[1]\n",
    "    img_crop = crops[short_name]\n",
    "    cropped = crop(image, img_crop['y_start']-cube_size, img_crop['y_end']+cube_size, \\\n",
    "                   img_crop['x_start']-cube_size, img_crop['x_end']+cube_size)\n",
    "    front = load_front_for_name(file_name)\n",
    "    front_adaptive = threshold_adaptive(front, 251, offset=5)  \n",
    "    # import pdb; pdb.set_trace()\n",
    "    cropped_adaptive = threshold_adaptive(cropped, 251, offset=5)\n",
    "    cropped_flipped_lr = cropped_adaptive[:,::-1]\n",
    "    offset_x_lr, offset_y_lr, val_lr = find_match(front_adaptive, cropped_flipped_lr)\n",
    "    cropped_flipped_ud = cropped_adaptive[:,::-1]\n",
    "    offset_x_ud, offset_y_ud, val_ud = find_match(front_adaptive, cropped_flipped_ud)\n",
    "\n",
    "    if (val_lr > val_ud):\n",
    "        return cropped_flipped_lr.shape[1], offset_x_lr, offset_y_lr, True\n",
    "    else:\n",
    "        return cropped_flipped_ud.shape[1], offset_x_ud, offset_y_ud, False\n",
    "    \n",
    "\n",
    "def extract_image_derivatives_orig(file_name):\n",
    "    image = load_img_for_name(file_name)\n",
    "    split = file_name.split(\"-\")\n",
    "    short_name = split[0] + split[1]\n",
    "    img_crop = crops[short_name]\n",
    "    cropped = crop(image, img_crop['y_start']-cube_size, img_crop['y_end']+cube_size, \\\n",
    "                   img_crop['x_start']-cube_size, img_crop['x_end']+cube_size)\n",
    "    front = load_front_for_name(file_name)\n",
    "    front_adaptive = threshold_adaptive(front, 251, offset=5)  \n",
    "    # import pdb; pdb.set_trace()\n",
    "    cropped_adaptive = threshold_adaptive(cropped, 251, offset=5)\n",
    "    cropped_flipped_lr = cropped_adaptive[:,::-1]\n",
    "    offset_x_lr, offset_y_lr, val_lr = find_match(front_adaptive, cropped_flipped_lr)\n",
    "    cropped_flipped_ud = cropped_adaptive[:,::-1]\n",
    "    offset_x_ud, offset_y_ud, val_ud = find_match(front_adaptive, cropped_flipped_ud)\n",
    "\n",
    "    if (val_lr > val_ud):\n",
    "        return front, cropped_flipped_lr, offset_x_lr, offset_y_lr\n",
    "    else:\n",
    "        return front, cropped_flipped_ud, offset_x_ud, offset_y_ud\n",
    "    \n",
    "    \n",
    "\n",
    "x1start = 0\n",
    "y1start = 0\n",
    "\n",
    "\n",
    "def get_cube_coordinates(file_name, cropped_width, offset_x, offset_y, cubex, cubey):\n",
    "    if file_name[0:file_name.rfind('-D')] not in no_rotate:\n",
    "        temp = cubex\n",
    "        cubex = cropped_width - cubey - cube_size\n",
    "        cubey = temp\n",
    "\n",
    "    reverse_cubex = x1start + offset_x + cube_size + (cropped_width - cubex - cube_size)\n",
    "    reverse_cubey = y1start + offset_y + cube_size + cubey\n",
    "    \n",
    "    return reverse_cubex, reverse_cubey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WRITE results for flip and match into a CSV file\n",
    "all_matches = pd.read_csv('20181020_212330_pairs_final.csv')\n",
    "for idx, row in all_matches.iterrows():\n",
    "    first_file_name = matchFirstFile[fragmanetAndSideKey]\n",
    "    first_cropped_width, first_offset_x, first_offset_y, first_is_horiz = \\\n",
    "        extract_image_derivatives(first_file_name)\n",
    "    second_file_name = matchSecondFile[fragmanetAndSideKey]\n",
    "    second_cropped_width, second_offset_x, second_offset_y, second_is_horiz = \\\n",
    "        extract_image_derivatives(second_file_name)\n",
    "\n",
    "all_matches.to_csv('20181020_212330_pairs_final_flipped.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WRITE results to a CSV file\n",
    "with open('cubes_X3_e.csv', 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',')\n",
    "    csvwriter.writerow([\"fragmanetAndSide\", \n",
    "                        \"fragment\", \n",
    "                        \"fragmentVote\",\n",
    "                        \"fragmentAndSideVote\",\n",
    "                        \"fragmentAndSideTrendVote\",\n",
    "                        \"fragmentAndSideTrendVoteStrict\",\n",
    "                        \"fragmentAndSideTrendVoteSync\",\n",
    "                        \"fitstFileName\",\n",
    "                        \"firstCroppedWidth\",\n",
    "                        \"firstOffsetX\",\n",
    "                        \"firstOffsetY\",\n",
    "                        \"firstHorizontalFlip\",\n",
    "                        \"secondFileName\",\n",
    "                        \"secondCroppedWidth\",\n",
    "                        \"secondOffsetX\",\n",
    "                        \"secondOffsetY\",\n",
    "                        \"secondHorizontalFlip\",\n",
    "                        \"fragmentAndSideTrend\",\n",
    "                        \"fragmentAndSideCubes\",\n",
    "                        \"origCoordinates\"])\n",
    "    for fragmanetAndSideKey in fragmentAndSideVote:\n",
    "        if fragmentAndSideTrendVoteSync[fragmanetAndSideKey] > 0:\n",
    "            print(fragmanetAndSideKey)\n",
    "\n",
    "            first_file_name = matchFirstFile[fragmanetAndSideKey]\n",
    "            first_cropped_width, first_offset_x, first_offset_y, first_is_horiz = \\\n",
    "                extract_image_derivatives(first_file_name)\n",
    "            second_file_name = matchSecondFile[fragmanetAndSideKey]\n",
    "            second_cropped_width, second_offset_x, second_offset_y, second_is_horiz = \\\n",
    "                extract_image_derivatives(second_file_name)\n",
    "\n",
    "            csvwriter.writerow([fragmanetAndSideKey, \n",
    "                                fragmentNames[fragmanetAndSideKey], \n",
    "                                fragmentVote[fragmentNames[fragmanetAndSideKey]],\n",
    "                                fragmentAndSideVote[fragmanetAndSideKey],\n",
    "                                fragmentAndSideTrendVote[fragmanetAndSideKey],\n",
    "                                fragmentAndSideTrendVoteStrict[fragmanetAndSideKey],\n",
    "                                fragmentAndSideTrendVoteSync[fragmanetAndSideKey],\n",
    "                                first_file_name,\n",
    "                                first_cropped_width,\n",
    "                                first_offset_x, \n",
    "                                first_offset_y,\n",
    "                                first_is_horiz,\n",
    "                                second_file_name,\n",
    "                                second_cropped_width,\n",
    "                                second_offset_x, \n",
    "                                second_offset_y, \n",
    "                                second_is_horiz,\n",
    "                                fragmentAndSideTrend[fragmanetAndSideKey],\n",
    "                                fragmentAndSideCubes[fragmanetAndSideKey],\n",
    "                                origCoordinates[fragmanetAndSideKey]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEBUG - don't run\n",
    "done = False\n",
    "for fragmanetAndSideKey in fragmentAndSideVote:\n",
    "    if fragmentAndSideTrendVoteSync[fragmanetAndSideKey] > 0 and not done:\n",
    "        # import pdb; pdb.set_trace()\n",
    "        file_name = matchFirstFile[fragmanetAndSideKey]\n",
    "        print(fragmanetAndSideKey)\n",
    "        print(file_name)\n",
    "        cropped_width, offset_x, offset_y = extract_image_derivatives(file_name)\n",
    "        done = True\n",
    "        front = load_front_for_name(file_name)\n",
    "        for cube_match in fragmentAndSideCubes[fragmanetAndSideKey]:\n",
    "            x_co, y_co = get_cube_coordinates(file_name, cropped_width, offset_x, offset_y, cube_match[0], cube_match[1])\n",
    "            fig = plt.figure(figsize=(20, 6))\n",
    "            ax2 = plt.subplot(1, 3, 1, adjustable='box-forced')\n",
    "            ax2.imshow(front, cmap=plt.cm.gray)\n",
    "            rect = plt.Rectangle((x_co, y_co), cube_size, cube_size, edgecolor='r', facecolor='none')\n",
    "            ax2.add_patch(rect)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEBUG - don't run\n",
    "for cube_match in fragmentAndSideCubes[fragmanetAndSideKey]:\n",
    "    draw_on_plot(plt, ax2, flipped, offset_x, offset_y, cube_match[0], cube_match[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
