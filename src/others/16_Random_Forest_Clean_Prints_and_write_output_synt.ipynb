{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tf_gpu2/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/envs/tf_gpu2/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/envs/tf_gpu2/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "# import pydot\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# Utility to store and load model from disk\n",
    "from sklearn.externals import joblib\n",
    "# write csv files\n",
    "import csv\n",
    "# Import charting lib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# UTIL\n",
    "def test_model(forest_model, test_features, test_labels):\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = np.round(forest_model.predict(test_features))\n",
    "\n",
    "    # Calculate the absolute errors\n",
    "    errors = abs(predictions - test_labels)\n",
    "\n",
    "    # Print out the mean absolute error (mae)\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 2))\n",
    "\n",
    "    # Calculate mean absolute percentage error (MAPE)\n",
    "    mape = 100 * (errors / test_labels)\n",
    "\n",
    "    # Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "    # Pull out one tree from the forest\n",
    "    #tree = forest_model.estimators_[5]\n",
    "    # print('The depth of this tree is:', tree.tree_.max_depth)\n",
    "\n",
    "    total_trues = sum(x == 2 for x in test_labels)\n",
    "    total_predictions = sum(x == 2 for x in predictions)\n",
    "    total_errors = sum(x == 1 for x in errors)\n",
    "    print('Total Samples:', len(test_labels))\n",
    "    print('Total Trues:', total_trues)\n",
    "    print('Total Predictions:', total_predictions)\n",
    "    print('Total Errors:', total_errors)\n",
    "\n",
    "    false_positive = sum(predict > label for predict, label in zip(predictions, test_labels))\n",
    "    false_negative = sum(predict < label for predict, label in zip(predictions, test_labels))\n",
    "    true_positive = total_predictions - false_positive\n",
    "    print('false_positive:', false_positive)\n",
    "    print('false_negative:', false_negative)\n",
    "    print('true_positive:', true_positive)\n",
    "    \n",
    "    print('>>>>>>>>>>>>>>>>>>>>')\n",
    "    for index, value in enumerate(zip(predictions, test_labels)):\n",
    "        if value[0] < value[1]:\n",
    "            print(test_features_[index,0])\n",
    "    print('>>>>>>>>>>>>>>>>>>>>')\n",
    "    \n",
    "    \n",
    "    precision = true_positive / total_predictions\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    print('precision:', precision)\n",
    "    print('recall:', recall)\n",
    "    return precision, recall\n",
    "\n",
    "def draw_tree(forest_model, test_features, test_labels): \n",
    "    importances = forest_model.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest_model.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(test_features.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(test_features.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(test_features.shape[1]), indices)\n",
    "    plt.xlim([-1, test_features.shape[1]])\n",
    "    plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fragmentAndSide',\n",
       " 'fragmentTotal',\n",
       " 'fragmentVote',\n",
       " 'devideVoteByTotal',\n",
       " 'fragmentAndSideVote',\n",
       " 'devideSideVoteBySideTotal',\n",
       " 'fragmentAndSideTrendVote',\n",
       " 'devideSideTrendVoteBySideTotal',\n",
       " 'fragmentAndSideTrendVoteStrict',\n",
       " 'devideSideTrendVoteStrictBySideTotal',\n",
       " 'fragmentAndSideTrendVoteSync',\n",
       " 'devideSideTrendVoteSyncBySideTotal',\n",
       " 'votesOverlapMax',\n",
       " 'divideOverlapMaxBySideTotal',\n",
       " 'votesOverlapHeight',\n",
       " 'votesSupportOverlapRect',\n",
       " 'divideSupportOverlapBySideTotal',\n",
       " 'divideSupportOverlapBySideVote']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the source data\n",
    "features = pd.read_csv('20181216_034921_pairs_final_enhanced_synt.csv') #20181020_212330_pairs_votes_enhanced\n",
    "\n",
    "# Remove the irrelevant texts from the features\n",
    "# axis 1 refers to the columns\n",
    "# features = features.drop('fragmanetAndSide', axis = 1)\n",
    "features = features.drop('fragment', axis = 1)\n",
    "features = features.drop('fragmentAndSideTotal', axis = 1)\n",
    "features = features.drop('fragmentAndSideTrend', axis = 1)\n",
    "features = features.drop('fragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('fragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('fragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('origCoordinates', axis = 1)\n",
    "features = features.drop(\"firstFileName\", axis = 1)\n",
    "features = features.drop(\"firstCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"firstOffsetX\", axis = 1)\n",
    "features = features.drop(\"firstOffsetY\", axis = 1)\n",
    "features = features.drop(\"firstHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"secondFileName\", axis = 1)\n",
    "features = features.drop(\"secondCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"secondOffsetX\", axis = 1)\n",
    "features = features.drop(\"secondOffsetY\", axis = 1)\n",
    "features = features.drop(\"secondHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"prediction\", axis = 1)\n",
    "\n",
    "# features = features.drop('fragmentTotal', axis = 1)\n",
    "# features = features.drop('fragmentAndSideVote', axis = 1)\n",
    "# features = features.drop('fragmentAndSideTrendVote', axis = 1)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "#features = pd.get_dummies(features)\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['class'])\n",
    "labels = labels + 1\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('class', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0\n",
      "Accuracy: 99.94 %.\n",
      "Total Samples: 839\n",
      "Total Trues: 41\n",
      "Total Predictions: 40\n",
      "Total Errors: 1\n",
      "false_positive: 0\n",
      "false_negative: 1\n",
      "true_positive: 40\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_6X3_3X2_0_PX303Fg006_6X3_4X2_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 1.0\n",
      "recall: 0.975609756097561\n",
      "Feature ranking:\n",
      "1. feature 12 (0.342662)\n",
      "2. feature 11 (0.240912)\n",
      "3. feature 15 (0.162103)\n",
      "4. feature 14 (0.157955)\n",
      "5. feature 16 (0.026478)\n",
      "6. feature 3 (0.017251)\n",
      "7. feature 5 (0.015074)\n",
      "8. feature 6 (0.008946)\n",
      "9. feature 4 (0.006686)\n",
      "10. feature 13 (0.006531)\n",
      "11. feature 0 (0.004792)\n",
      "12. feature 9 (0.003860)\n",
      "13. feature 7 (0.002468)\n",
      "14. feature 1 (0.001452)\n",
      "15. feature 8 (0.001114)\n",
      "16. feature 10 (0.001093)\n",
      "17. feature 2 (0.000622)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest 1st model\n",
    "# Split the data into training and testing sets\n",
    "train_features_, test_features_, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "train_features = train_features_[:,1:] # remove the fragmentAndSide column which is the label\n",
    "test_features = test_features_[:,1:] # remove the fragmentAndSide column which is the label\n",
    "\n",
    "# Instantiate model \n",
    "rf = RandomForestClassifier(n_estimators= 1000, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf, test_features, test_labels)\n",
    "draw_tree(rf, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0\n",
      "Accuracy: 99.94 %.\n",
      "Total Samples: 815\n",
      "Total Trues: 35\n",
      "Total Predictions: 34\n",
      "Total Errors: 1\n",
      "false_positive: 0\n",
      "false_negative: 1\n",
      "true_positive: 34\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_5X3_3X1_1_PX303Fg006_5X3_4X1_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 1.0\n",
      "recall: 0.971428571429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.97142857142857142)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoostClassifier model \n",
    "ab = AdaBoostClassifier(n_estimators= 1000, learning_rate=0.8)\n",
    "\n",
    "ab.fit(train_features, train_labels)\n",
    "\n",
    "test_model(ab, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0\n",
      "Accuracy: 99.88 %.\n",
      "Total Samples: 815\n",
      "Total Trues: 35\n",
      "Total Predictions: 33\n",
      "Total Errors: 2\n",
      "false_positive: 0\n",
      "false_negative: 2\n",
      "true_positive: 33\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_6X3_1X1_1_PX303Fg006_6X3_2X1_0\n",
      "PX303Fg006_5X3_3X1_1_PX303Fg006_5X3_4X1_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 1.0\n",
      "recall: 0.942857142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.94285714285714284)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BaggingClassifier model \n",
    "bc = BaggingClassifier(n_estimators= 1000)\n",
    "\n",
    "bc.fit(train_features, train_labels)\n",
    "\n",
    "test_model(bc, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0\n",
      "Accuracy: 99.88 %.\n",
      "Total Samples: 815\n",
      "Total Trues: 35\n",
      "Total Predictions: 33\n",
      "Total Errors: 2\n",
      "false_positive: 0\n",
      "false_negative: 2\n",
      "true_positive: 33\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_6X3_1X1_1_PX303Fg006_6X3_2X1_0\n",
      "PX303Fg006_5X3_3X1_1_PX303Fg006_5X3_4X1_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 1.0\n",
      "recall: 0.942857142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.94285714285714284)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExtraTreesClassifier model \n",
    "et = ExtraTreesClassifier(n_estimators= 1000)\n",
    "\n",
    "et.fit(train_features, train_labels)\n",
    "\n",
    "test_model(et, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0\n",
      "Accuracy: 99.88 %.\n",
      "Total Samples: 815\n",
      "Total Trues: 35\n",
      "Total Predictions: 33\n",
      "Total Errors: 2\n",
      "false_positive: 0\n",
      "false_negative: 2\n",
      "true_positive: 33\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_6X3_1X1_1_PX303Fg006_6X3_2X1_0\n",
      "PX303Fg006_5X3_3X1_1_PX303Fg006_5X3_4X1_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 1.0\n",
      "recall: 0.942857142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.94285714285714284)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoostingClassifier model \n",
    "gb = GradientBoostingClassifier(n_estimators= 1000)\n",
    "\n",
    "gb.fit(train_features, train_labels)\n",
    "\n",
    "test_model(gb, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0\n",
      "Accuracy: 99.94 %.\n",
      "Total Samples: 815\n",
      "Total Trues: 33\n",
      "Total Predictions: 32\n",
      "Total Errors: 1\n",
      "false_positive: 0\n",
      "false_negative: 1\n",
      "true_positive: 32\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_3X2_1X1_1_PX303Fg006_3X2_2X1_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 1.0\n",
      "recall: 0.969696969697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.96969696969696972)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VotingClassifier model \n",
    "vt = VotingClassifier(estimators=[('ab', ab), ('rf', rf), ('bc', bc), ('et', et), ('gb', gb)], voting='soft', n_jobs=-1)\n",
    "\n",
    "vt.fit(train_features, train_labels)\n",
    "\n",
    "test_model(vt, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_predict\n",
    "# from sklearn import metrics\n",
    "# predicted = cross_val_predict(rf, test_features, test_labels, cv=5)\n",
    "# metrics.accuracy_score(test_labels, np.round(predicted)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest 2nd variation of model - just for reference - not used\n",
    "rf_new = RandomForestRegressor(n_estimators = 1000, criterion = 'mse', max_depth = None, \n",
    "                               min_samples_split = 2, min_samples_leaf = 1)\n",
    "rf_new.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf_new, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest 3rd model - Limit depth of tree to 2 levels - not used\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state=42)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf_small, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rndFstBasic2.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally - use the 1st model and this time train on the entire set \n",
    "fit_features = features[:,1:] # remove the fragmentAndSide column which is the label\n",
    "\n",
    "rf.fit(fit_features, labels);\n",
    "\n",
    "joblib.dump(rf, 'rndFstBasic2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Run on the output of the voting and classify them\n",
    "# Read in data as pandas dataframe\n",
    "orig_features = pd.read_csv('20181216_034921_pairs_final_enhanced_synt.csv') #('20181213_031300_pairs_final_flipped_enhanced.csv')\n",
    "\n",
    "# Remove the irrelevant texts from the features\n",
    "# axis 1 refers to the columns\n",
    "features = orig_features.drop('fragmentAndSide', axis = 1)\n",
    "features = features.drop('fragment', axis = 1)\n",
    "features = features.drop('fragmentAndSideTotal', axis = 1)\n",
    "features = features.drop('fragmentAndSideTrend', axis = 1)\n",
    "features = features.drop('fragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('fragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('fragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('origCoordinates', axis = 1)\n",
    "features = features.drop(\"firstFileName\", axis = 1)\n",
    "features = features.drop(\"firstCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"firstOffsetX\", axis = 1)\n",
    "features = features.drop(\"firstOffsetY\", axis = 1)\n",
    "features = features.drop(\"firstHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"secondFileName\", axis = 1)\n",
    "features = features.drop(\"secondCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"secondOffsetX\", axis = 1)\n",
    "features = features.drop(\"secondOffsetY\", axis = 1)\n",
    "features = features.drop(\"secondHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"class\", axis = 1)\n",
    "features = features.drop(\"prediction\", axis = 1)\n",
    "\n",
    "forest_model = joblib.load('rndFstBasic2.pkl') \n",
    "\n",
    "predictions = np.round(forest_model.predict(features))-1\n",
    "orig_features[\"prediction\"] = predictions\n",
    "filtered = orig_features # [orig_features[\"prediction\"] == 1]\n",
    "filtered.to_csv('20181216_034921_pairs_final_enhanced_final_synt2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
