{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fragmanetAndSide</th>\n",
       "      <th>fragment</th>\n",
       "      <th>class</th>\n",
       "      <th>fragmentVote</th>\n",
       "      <th>fragmentAndSideVote</th>\n",
       "      <th>fragmentAndSideTrendVote</th>\n",
       "      <th>fragmentAndSideTrendVoteStrict</th>\n",
       "      <th>fragmentAndSideTrendVoteSync</th>\n",
       "      <th>fragmentAndSideTrend</th>\n",
       "      <th>fragmentAndSideCubes</th>\n",
       "      <th>origCoordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PX303Fg006_7X4_1X3_1_PX303Fg006_7X4_6X3_1</td>\n",
       "      <td>PX303Fg006_7X4_1X3_PX303Fg006_7X4_6X3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[False, 1, 0], [False, 1, 1]]</td>\n",
       "      <td>[[1078, 250, 590, 0], [1078, 250, 590, 250]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PX303Fg006_4X4_0X3_1_PX303Fg006_4X4_3X0_1</td>\n",
       "      <td>PX303Fg006_4X4_0X3_PX303Fg006_4X4_3X0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[False, 0, 0], [False, 0, 1], [False, 1, 0], ...</td>\n",
       "      <td>[[794, 0, 1254, 250], [794, 250, 1254, 250], [...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PX303Fg006_7X4_1X0_0_PX303Fg006_7X4_6X3_1</td>\n",
       "      <td>PX303Fg006_7X4_1X0_PX303Fg006_7X4_6X3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[[False, 0, 0], [False, 0, 1], [False, 1, 0], ...</td>\n",
       "      <td>[[50, 250, 590, 250], [50, 250, 590, 0], [50, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PX303Fg006_8X3_2X1_0_PX303Fg006_8X3_3X1_0</td>\n",
       "      <td>PX303Fg006_8X3_2X1_PX303Fg006_8X3_3X1</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[[False, 0, 0], [False, 0, 1], [False, 1, 0], ...</td>\n",
       "      <td>[[50, 250, 50, 0], [50, 0, 50, 0], [50, 250, 5...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PX303Fg006_3X4_0X1_0_PX303Fg006_3X4_1X3_0</td>\n",
       "      <td>PX303Fg006_3X4_0X1_PX303Fg006_3X4_1X3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[[False, 0, 0], [False, 0, 1], [False, 1, 0], ...</td>\n",
       "      <td>[[50, 0, 50, 0], [50, 250, 50, 250], [50, 0, 5...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            fragmanetAndSide  \\\n",
       "0  PX303Fg006_7X4_1X3_1_PX303Fg006_7X4_6X3_1   \n",
       "1  PX303Fg006_4X4_0X3_1_PX303Fg006_4X4_3X0_1   \n",
       "2  PX303Fg006_7X4_1X0_0_PX303Fg006_7X4_6X3_1   \n",
       "3  PX303Fg006_8X3_2X1_0_PX303Fg006_8X3_3X1_0   \n",
       "4  PX303Fg006_3X4_0X1_0_PX303Fg006_3X4_1X3_0   \n",
       "\n",
       "                                fragment  class  fragmentVote  \\\n",
       "0  PX303Fg006_7X4_1X3_PX303Fg006_7X4_6X3      0             6   \n",
       "1  PX303Fg006_4X4_0X3_PX303Fg006_4X4_3X0      0            16   \n",
       "2  PX303Fg006_7X4_1X0_PX303Fg006_7X4_6X3      0             8   \n",
       "3  PX303Fg006_8X3_2X1_PX303Fg006_8X3_3X1      0           147   \n",
       "4  PX303Fg006_3X4_0X1_PX303Fg006_3X4_1X3      0            16   \n",
       "\n",
       "   fragmentAndSideVote  fragmentAndSideTrendVote  \\\n",
       "0                    2                         2   \n",
       "1                    4                         4   \n",
       "2                    4                         4   \n",
       "3                    4                         4   \n",
       "4                    4                         4   \n",
       "\n",
       "   fragmentAndSideTrendVoteStrict  fragmentAndSideTrendVoteSync  \\\n",
       "0                               0                             0   \n",
       "1                               0                             0   \n",
       "2                               6                             3   \n",
       "3                               6                             3   \n",
       "4                               6                             3   \n",
       "\n",
       "                                fragmentAndSideTrend  \\\n",
       "0                     [[False, 1, 0], [False, 1, 1]]   \n",
       "1  [[False, 0, 0], [False, 0, 1], [False, 1, 0], ...   \n",
       "2  [[False, 0, 0], [False, 0, 1], [False, 1, 0], ...   \n",
       "3  [[False, 0, 0], [False, 0, 1], [False, 1, 0], ...   \n",
       "4  [[False, 0, 0], [False, 0, 1], [False, 1, 0], ...   \n",
       "\n",
       "                                fragmentAndSideCubes origCoordinates  \n",
       "0       [[1078, 250, 590, 0], [1078, 250, 590, 250]]              []  \n",
       "1  [[794, 0, 1254, 250], [794, 250, 1254, 250], [...              []  \n",
       "2  [[50, 250, 590, 250], [50, 250, 590, 0], [50, ...              []  \n",
       "3  [[50, 250, 50, 0], [50, 0, 50, 0], [50, 250, 5...              []  \n",
       "4  [[50, 0, 50, 0], [50, 250, 50, 250], [50, 0, 5...              []  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Read in data as pandas dataframe and display first 5 rows\n",
    "features = pd.read_csv('votes_cubes_match_synt.csv')\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our features is: (7622, 11)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of our features is:', features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>fragmentVote</th>\n",
       "      <th>fragmentAndSideVote</th>\n",
       "      <th>fragmentAndSideTrendVote</th>\n",
       "      <th>fragmentAndSideTrendVoteStrict</th>\n",
       "      <th>fragmentAndSideTrendVoteSync</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  fragmentVote  fragmentAndSideVote  fragmentAndSideTrendVote  \\\n",
       "0      0             6                    2                         2   \n",
       "1      0            16                    4                         4   \n",
       "2      0             8                    4                         4   \n",
       "3      0           147                    4                         4   \n",
       "4      0            16                    4                         4   \n",
       "\n",
       "   fragmentAndSideTrendVoteStrict  fragmentAndSideTrendVoteSync  \n",
       "0                               0                             0  \n",
       "1                               0                             0  \n",
       "2                               6                             3  \n",
       "3                               6                             3  \n",
       "4                               6                             3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the irrelevant texts from the features\n",
    "# axis 1 refers to the columns\n",
    "features = features.drop('fragmanetAndSide', axis = 1)\n",
    "features = features.drop('fragment', axis = 1)\n",
    "features = features.drop('fragmentAndSideTrend', axis = 1)\n",
    "features = features.drop('fragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('origCoordinates', axis = 1)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "features = pd.get_dummies(features)\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features after one-hot encoding: (7622, 6)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of features after one-hot encoding:', features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['class'])\n",
    "labels = labels + 1\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('class', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25,\n",
    "                                                                           random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (5716, 5)\n",
      "Training Labels Shape: (5716,)\n",
      "Testing Features Shape: (1906, 5)\n",
      "Testing Labels Shape: (1906,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The baseline predictions are the historical averages\n",
    "# baseline_preds = test_features[:, feature_list.index('average')]\n",
    "\n",
    "# # Baseline errors, and display average baseline error\n",
    "# baseline_errors = abs(baseline_preds - test_labels)\n",
    "# print('Average baseline error: ', round(np.mean(baseline_errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model \n",
    "rf = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.68 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "\n",
    "# # Export the image to a dot file\n",
    "# export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "\n",
    "# # Use dot file to create a graph\n",
    "# (graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "\n",
    "# # Write graph to a png file\n",
    "# graph.write_png('tree.png'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![Decision Tree](tree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The depth of this tree is: 9\n"
     ]
    }
   ],
   "source": [
    "print('The depth of this tree is:', tree.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create models with different hyperparameters to try and boost performance. The only way to find the best ones\n",
    "are to try a few and evaluate them! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_new = RandomForestRegressor(n_estimators = 100, criterion = 'mse', max_depth = None, \n",
    "                               min_samples_split = 2, min_samples_leaf = 1)\n",
    "rf_new.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf_new.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.67 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller tree for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The depth of this tree is: 11\n"
     ]
    }
   ],
   "source": [
    "tree = rf_new.estimators_[5]\n",
    "print('The depth of this tree is:', tree.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit depth of tree to 2 levels\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state=42)\n",
    "rf_small.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf_small.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.48 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 4.0\n"
     ]
    }
   ],
   "source": [
    "predictions2 = np.round(predictions)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions2 - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.sum(errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.87 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_indexes = np.nonzero(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falsed = test_labels[match_indexes]\n",
    "falsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x == 2 for x in test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The depth of this tree is: 11\n"
     ]
    }
   ],
   "source": [
    "# Extract the small tree\n",
    "tree = rf_new.estimators_[5]\n",
    "print('The depth of this tree is:', tree.tree_.max_depth)\n",
    "\n",
    "# # Save the tree as a png image\n",
    "# export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "\n",
    "# (graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "\n",
    "# graph.write_png('small_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Small Decision Tree](small_tree.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated Version of Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Annotated Decision Tree](small_tree_annotated.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "\n",
    "# Extract the two most important features\n",
    "important_indices = [feature_list.index('temp_1'), feature_list.index('average')]\n",
    "train_important = train_features[:, important_indices]\n",
    "test_important = test_features[:, important_indices]\n",
    "\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, train_labels)\n",
    "\n",
    "# Make predictions and determine the error\n",
    "predictions = rf_most_important.predict(test_important)\n",
    "\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "mape = np.mean(100 * (errors / test_labels))\n",
    "accuracy = 100 - mape\n",
    "\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Dates of training values\n",
    "months = features[:, feature_list.index('month')]\n",
    "days = features[:, feature_list.index('day')]\n",
    "years = features[:, feature_list.index('year')]\n",
    "\n",
    "# List and then convert to datetime object\n",
    "dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
    "dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
    "\n",
    "# Dataframe with true values and dates\n",
    "true_data = pd.DataFrame(data = {'date': dates, 'actual': labels})\n",
    "\n",
    "# Dates of predictions\n",
    "months = test_features[:, feature_list.index('month')]\n",
    "days = test_features[:, feature_list.index('day')]\n",
    "years = test_features[:, feature_list.index('year')]\n",
    "\n",
    "# Column of dates\n",
    "test_dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
    "\n",
    "# Convert to datetime objects\n",
    "test_dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in test_dates]\n",
    "\n",
    "# Dataframe with predictions and dates\n",
    "predictions_data = pd.DataFrame(data = {'date': test_dates, 'prediction': predictions}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the actual values\n",
    "plt.plot(true_data['date'], true_data['actual'], 'b-', label = 'actual')\n",
    "\n",
    "# Plot the predicted values\n",
    "plt.plot(predictions_data['date'], predictions_data['prediction'], 'ro', label = 'prediction')\n",
    "plt.xticks(rotation = '60'); \n",
    "plt.legend()\n",
    "\n",
    "# Graph labels\n",
    "plt.xlabel('Date'); plt.ylabel('Maximum Temperature (F)'); plt.title('Actual and Predicted Values');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make the data accessible for plotting\n",
    "true_data['temp_1'] = features[:, feature_list.index('temp_1')]\n",
    "true_data['average'] = features[:, feature_list.index('average')]\n",
    "true_data['friend'] = features[:, feature_list.index('friend')]\n",
    "\n",
    "# Plot all the data as lines\n",
    "plt.plot(true_data['date'], true_data['actual'], 'b-', label  = 'actual', alpha = 1.0)\n",
    "plt.plot(true_data['date'], true_data['temp_1'], 'y-', label  = 'temp_1', alpha = 1.0)\n",
    "plt.plot(true_data['date'], true_data['average'], 'k-', label = 'average', alpha = 0.8)\n",
    "plt.plot(true_data['date'], true_data['friend'], 'r-', label = 'friend', alpha = 0.3)\n",
    "\n",
    "# Formatting plot\n",
    "plt.legend(); plt.xticks(rotation = '60');\n",
    "\n",
    "# Lables and title\n",
    "plt.xlabel('Date'); plt.ylabel('Maximum Temperature (F)'); plt.title('Actual Max Temp and Variables');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
